{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.layers import Layer\n",
    "from keras.layers import *\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.utils.generic_utils import CustomObjectScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_edsr_48w_48h.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuqiao/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeplabv3plus_mobv2_1920w_1080h.h5\n",
      "relu6 model\n",
      "Deeplabv3plus_mobv2_512w_512h.h5\n",
      "relu6 model\n",
      "Deeplabv3plus_512w_512h.h5\n",
      "Deeplabv3plus_mobv2_960w_720h.h5\n",
      "relu6 model\n",
      "Deeplabv3_512w_512h.h5\n",
      "img_pspnet_473w_473h.h5\n",
      "MobileNetV2_noAct_224w_224h.h5\n",
      "other error\n",
      "failed case: MobileNetV2_noAct_224w_224h.h5\n",
      "ResNet101_224w_224h.h5\n",
      "ResNext101_224w_224h.h5\n",
      "ResNet50_960w_720h.h5\n",
      "ResNext50_224w_224h.h5\n",
      "ResNet50_1920w_1080h.h5\n",
      "ResNet152_224w_224h.h5\n",
      "Inceptionv4_299w_299h.h5\n",
      "MobileNetv2_960w_720h.h5\n",
      "MobileNetv2_1920w_1080h.h5\n",
      "MobileNetv2_224w_224h.h5\n",
      "NasNet_224w_224h.h5\n",
      "Inceptionv3_960w_720h.h5\n",
      "Inceptionv3_224w_224h.h5\n",
      "Inceptionv3_1920w_1080h.h5\n",
      "Inceptionv1_224w_224h.h5\n",
      "MobileNet_224w_224h.h5\n",
      "MobileNet_1920w_1080h.h5\n",
      "MobileNet_960w_720h.h5\n",
      "PVAnet_fasterRCNN_rpn_640w_480h.h5\n",
      "other error\n",
      "failed case: PVAnet_fasterRCNN_rpn_640w_480h.h5\n",
      "ShuffleNet-2_224w_224h.h5\n",
      "other error\n",
      "failed case: ShuffleNet-2_224w_224h.h5\n",
      "ShuffleNet-4_224w_224h.h5\n",
      "other error\n",
      "failed case: ShuffleNet-4_224w_224h.h5\n",
      "ShuffleNet-8_224w_224h.h5\n",
      "other error\n",
      "failed case: ShuffleNet-8_224w_224h.h5\n",
      "vgg16_224w_224h.h5\n",
      "Xception_224w_224h.h5\n",
      "DenseNet_224w_224h.h5\n",
      "img_ocr_256w_64h.h5\n",
      "FD_160w_160h.h5\n",
      "lstm_attention_224w_224h.h5\n",
      "mobilenetv1_ssd_reduced_960w_720h.h5\n",
      "relu6 model\n",
      "mobilenetv1_ssd_reduced_640w_480h.h5\n",
      "relu6 model\n",
      "PNet_224w_224h.h5\n",
      "PVAnet_fasterRCNN_rcnn_40w_30h.h5\n",
      "valueError other cases\n",
      "failed case: PVAnet_fasterRCNN_rcnn_40w_30h.h5\n",
      "mobilenetv1_ssd_960w_720h.h5\n",
      "relu6 model\n",
      "mobilenetv1_ssd_640w_480h.h5\n",
      "relu6 model\n",
      "mobilenetv1_ssd_224w_224h.h5\n",
      "relu6 model\n",
      "RNet_224w_224h.h5\n",
      "mobilenetv2_ssdlite_960w_720h.h5\n",
      "mobilenetv2_ssdlite_640w_480h.h5\n",
      "ONet_224w_224h.h5\n",
      "mobilenetv2_ssd_960w_720h.h5\n",
      "mobilenetv2_ssd_640w_480h.h5\n",
      "mobilenetv2_retinanet_1000w_800h.h5\n",
      "valueError other cases\n",
      "failed case: mobilenetv2_retinanet_1000w_800h.h5\n",
      "ssd512_512w_512h.h5\n",
      "ssd300_300w_300h.h5\n",
      "yolov2_960w_736h.h5\n",
      "other error\n",
      "failed case: yolov2_960w_736h.h5\n",
      "yolov2_608w_608h.h5\n",
      "other error\n",
      "failed case: yolov2_608w_608h.h5\n",
      "yolov2_640w_480h.h5\n",
      "other error\n",
      "failed case: yolov2_640w_480h.h5\n",
      "tiny_yolo_416w_416h.h5\n",
      "SRCNN_300w_300h.h5\n",
      "VDSR_vgg19_192w_192h.h5\n",
      "Inception_resnet_v1_299w_299h.h5\n",
      "SRGAN_512w_512h.h5\n",
      "ICNet_384w_384h.h5\n",
      "Resnet_12_192w_128h.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = './new_network'\n",
    "header_set = set()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df.index.name = 'Model_Name'\n",
    "df.reset_index(inplace=True)\n",
    "df['Model_Class'] = ''\n",
    "\n",
    "idx = 0\n",
    "for model_class in os.listdir(root):\n",
    "    # open detectron, fasterrcnn\n",
    "    if os.path.isdir(root + '/' + model_class):\n",
    "        for model_dir in os.listdir(root + '/' + model_class):\n",
    "            if os.path.isdir(root + '/' + model_class + '/' + model_dir):\n",
    "                for model_file in os.listdir(root + '/' + model_class + '/' + model_dir):\n",
    "                    \n",
    "                    if model_file.endswith('.h5') or model_file.endswith('.hdf5'):\n",
    "                        print(model_file)\n",
    "                        try:\n",
    "                            model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                        except ValueError as e:\n",
    "                            if 'relu6' in str(e): #or ('relu6') in e:\n",
    "                                print('relu6 model')\n",
    "                                with CustomObjectScope({'relu6': keras.layers.ReLU(6.)}): #,'DepthwiseConv2D': keras.layers.DepthwiseConv2D}):\n",
    "                                    model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                            else:\n",
    "                                print('valueError other cases')\n",
    "                                df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                                print(\"failed case:\", model_file)\n",
    "                                continue\n",
    "\n",
    "                        except:\n",
    "                            print('other error')\n",
    "                            df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                            print(\"failed case:\", model_file)\n",
    "                            continue\n",
    "                        \n",
    "                        df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                        df.loc[idx+1 , ['Model_Class']] = model_class\n",
    "                        #print(model_file)\n",
    "                        operation_set = set() # for this model\n",
    "                        layers = model.layers\n",
    "                        idx = idx + 1\n",
    "                        for layer in layers:\n",
    "                            operation_name = layer.__class__.__name__\n",
    "                            if operation_name in header_set:\n",
    "                                pass\n",
    "                            else:\n",
    "                                header_set.add(operation_name)\n",
    "                                df[operation_name] = '' # add new type of operation at header\n",
    "                                \n",
    "                            if operation_name in operation_set:\n",
    "                                pass\n",
    "                            else:\n",
    "                                operation_set.add(operation_name)\n",
    "                                df.loc[df['Model_Name'] == model_file, [operation_name]]= 'YES'\n",
    "                            \n",
    "df.to_csv('Operation_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res50_1.00_3_512_(112%, 112, 3)_0.996_0.995_310.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuqiao/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res18_1.00_4_512_(112,112,3)_0.988_0.986_3.hdf5\n",
      "res34_1.00_3_512_(112, 112, 3)_0.991_0.991_104.hdf5\n",
      "res50_1.00_3_512_(112,112,3)_0.995_0.993_130.hdf5\n",
      "res100_1.00_3_512_(112,112,3)_0.995_0.995_40.hdf5\n",
      "res34_1.00_3_512_(112, 112, 3)_0.994_0.993_119.hdf5\n",
      "res28_3_256_0.988_0.979_142.hdf5\n"
     ]
    }
   ],
   "source": [
    "root = './new_network'\n",
    "df = pd.read_csv('Operation_Summary.csv')\n",
    "header_set = set(df.columns)\n",
    "idx = len(df)\n",
    "for model_class in os.listdir(root):\n",
    "    # open detectron, fasterrcnn\n",
    "    if os.path.isdir(root + '/' + model_class):\n",
    "        for model_dir in os.listdir(root + '/' + model_class):\n",
    "            if os.path.isdir(root + '/' + model_class + '/' + model_dir):\n",
    "                for model_file in os.listdir(root + '/' + model_class + '/' + model_dir):\n",
    "                    \n",
    "                    if model_file.endswith('.hdf5'):\n",
    "                        print(model_file)\n",
    "                        try:\n",
    "                            model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                        except ValueError as e:\n",
    "                            if 'relu6' in str(e): #or ('relu6') in e:\n",
    "                                print('relu6 model')\n",
    "                                with CustomObjectScope({'relu6': keras.layers.ReLU(6.)}): #,'DepthwiseConv2D': keras.layers.DepthwiseConv2D}):\n",
    "                                    model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                            else:\n",
    "                                print('valueError other cases')\n",
    "                                df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                                print(\"failed case:\", model_file)\n",
    "                                continue\n",
    "\n",
    "                        except:\n",
    "                            print('other error')\n",
    "                            df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                            print(\"failed case:\", model_file)\n",
    "                            continue\n",
    "                        \n",
    "                        df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                        df.loc[idx+1 , ['Model_Class']] = model_class\n",
    "                        #print(model_file)\n",
    "                        operation_set = set() # for this model\n",
    "                        layers = model.layers\n",
    "                        idx = idx + 1\n",
    "                        for layer in layers:\n",
    "                            operation_name = layer.__class__.__name__\n",
    "                            if operation_name in header_set:\n",
    "                                pass\n",
    "                            else:\n",
    "                                header_set.add(operation_name)\n",
    "                                df[operation_name] = '' # add new type of operation at header\n",
    "                                \n",
    "                            if operation_name in operation_set:\n",
    "                                pass\n",
    "                            else:\n",
    "                                operation_set.add(operation_name)\n",
    "                                df.loc[df['Model_Name'] == model_file, [operation_name]]= 'YES'\n",
    "                            \n",
    "df.to_csv('Operation_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detectron_frcnn_resnet50v1c4_640w_800h.h5\n",
      "detectron_frcnn_resnet50v1c4_head_600w_800h.h5\n",
      "detectron_frcnn_resnet50v1c4_head_640w_800h.h5\n",
      "detectron_frcnn_resnet50v1c4_600w_800h.h5\n",
      "detectron_fpn_mfrcnn_resnet101v1_head_640w_800h.h5\n",
      "detectron_fpn_mfrcnn_resnet101v1_640w_800h.h5\n",
      "detectron_fpn_mfrcnn_resnet50v1_head_640w_800h.h5\n",
      "detectron_fpn_mfrcnn_resnet50v1_640w_800h.h5\n",
      "detectron_fpn_frcnn_resnet101v1_head_640w_800h.h5\n",
      "detectron_fpn_frcnn_resnet101v1_640w_800h.h5\n",
      "detectron_mfrcnn_resnet50v1c4_head_640w_800h.h5\n",
      "detectron_mfrcnn_resnet50v1c4_640w_800h.h5\n",
      "detectron_fpn_frcnn_resnet50v1_head_640w_800h.h5\n",
      "detectron_fpn_frcnn_resnet50v1_640w_800h.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('Operation_Summary.csv')\n",
    "header_set = set(df.columns)\n",
    "idx = len(df)\n",
    "root = '.'\n",
    "model_class = 'Detectron'\n",
    "\n",
    "if os.path.isdir(root + '/' + model_class):\n",
    "    for model_dir in os.listdir(root + '/' + model_class):\n",
    "        if os.path.isdir(root + '/' + model_class + '/' + model_dir):\n",
    "            for model_file in os.listdir(root + '/' + model_class + '/' + model_dir):\n",
    "\n",
    "                if model_file.endswith('.h5') or model_file.endswith('.hdf5'):\n",
    "                    print(model_file)\n",
    "                    try:\n",
    "                        model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                    except ValueError as e:\n",
    "                        if 'relu6' in str(e): #or ('relu6') in e:\n",
    "                            print('relu6 model')\n",
    "                            with CustomObjectScope({'relu6': keras.layers.ReLU(6.)}): #,'DepthwiseConv2D': keras.layers.DepthwiseConv2D}):\n",
    "                                model = load_model(root + '/' + model_class + '/' + model_dir + '/' + model_file)\n",
    "                        else:\n",
    "                            print('valueError other cases')\n",
    "                            df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                            print(\"failed case:\", model_file)\n",
    "                            continue\n",
    "\n",
    "                    except:\n",
    "                        print('other error')\n",
    "                        df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                        print(\"failed case:\", model_file)\n",
    "                        continue\n",
    "\n",
    "                    df.loc[idx+1 , ['Model_Name']] = model_file\n",
    "                    df.loc[idx+1 , ['Model_Class']] = model_class\n",
    "                    #print(model_file)\n",
    "                    operation_set = set() # for this model\n",
    "                    layers = model.layers\n",
    "                    idx = idx + 1\n",
    "                    for layer in layers:\n",
    "                        operation_name = layer.__class__.__name__\n",
    "                        if operation_name in header_set:\n",
    "                            pass\n",
    "                        else:\n",
    "                            header_set.add(operation_name)\n",
    "                            df[operation_name] = '' # add new type of operation at header\n",
    "\n",
    "                        if operation_name in operation_set:\n",
    "                            pass\n",
    "                        else:\n",
    "                            operation_set.add(operation_name)\n",
    "                            df.loc[df['Model_Name'] == model_file, [operation_name]]= 'YES'\n",
    "                            \n",
    "df.to_csv('Operation_Summary.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
